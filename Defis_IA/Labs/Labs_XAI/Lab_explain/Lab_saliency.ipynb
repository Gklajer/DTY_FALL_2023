{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='./Figs/cs-logo.png' width=200></center>\n",
    "\n",
    "\n",
    "\n",
    "<h6><center></center></h6>\n",
    "\n",
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>eXplainable AI- Activity 4 : A small tour on saliency masks</center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>\n",
    "\n",
    "\n",
    "The objective of this notebook is to practice saliency maps using the [PAIRML](https://pair.withgoogle.com/tools/) saliency library available [here](https://github.com/PAIR-code/saliency) and tensorflow2.\n",
    "\n",
    "\n",
    "First, install the `saliency` pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import useful packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate imports.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from matplotlib import pylab as P\n",
    "\n",
    "# From our repository.\n",
    "import saliency.core as saliency\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of the notebook, you will have to use some functions to :\n",
    "+ display an image\n",
    "+ display an heat map or an explanation map\n",
    "+ Load an image\n",
    "+ Preprocess an image.\n",
    "\n",
    "Thes utility functions are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate methods.\n",
    "def ShowImage(im, title='', ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "  P.imshow(im)\n",
    "  P.title(title)\n",
    "\n",
    "def ShowGrayscaleImage(im, title='', ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "\n",
    "  P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n",
    "  P.title(title)\n",
    "\n",
    "def ShowHeatMap(im, title, ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "  P.imshow(im, cmap='inferno')\n",
    "  P.title(title)\n",
    "\n",
    "def ShowDivergingImage(grad, title='', percentile=99, ax=None):  \n",
    "  if ax is None:\n",
    "    fig, ax = P.subplots()\n",
    "  else:\n",
    "    fig = ax.figure\n",
    "  \n",
    "  P.axis('off')\n",
    "  divider = make_axes_locatable(ax)\n",
    "  cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "  im = ax.imshow(grad, cmap=P.cm.coolwarm, vmin=-1, vmax=1)\n",
    "  fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "  P.title(title)\n",
    "\n",
    "def LoadImage(file_path):\n",
    "  im = PIL.Image.open(file_path)\n",
    "  im = im.resize((224,224))\n",
    "  im = np.asarray(im)\n",
    "  return im\n",
    "\n",
    "def PreprocessImage(im):\n",
    "  im = tf.keras.applications.vgg16.preprocess_input(im)\n",
    "  return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the VGG16 model for ImageNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "conv_layer = m.get_layer('block5_conv3')\n",
    "model = tf.keras.models.Model([m.inputs], [conv_layer.output, m.output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`call_model_function` is how we pass inputs to our model and receive outputs necessary to computer saliency masks. The description of this method and necessary outputs is in the base CoreSaliency description, as well as separately for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx_str = 'class_idx_str'\n",
    "def call_model_function(images, call_model_args=None, expected_keys=None):\n",
    "    target_class_idx =  call_model_args[class_idx_str]\n",
    "    images = tf.convert_to_tensor(images)\n",
    "    with tf.GradientTape() as tape:\n",
    "        if expected_keys==[saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
    "            tape.watch(images)\n",
    "            _, output_layer = model(images)\n",
    "            output_layer = output_layer[:,target_class_idx]\n",
    "            gradients = np.array(tape.gradient(output_layer, images))\n",
    "            return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
    "        else:\n",
    "            conv_layer, output_layer = model(images)\n",
    "            gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
    "            return {saliency.base.CONVOLUTION_LAYER_VALUES: conv_layer,\n",
    "                    saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an image and infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "im_orig = LoadImage('./doberman.png')\n",
    "im = PreprocessImage(im_orig)\n",
    "\n",
    "# Show the image\n",
    "ShowImage(im_orig)\n",
    "\n",
    "_, predictions = model(np.array([im]))\n",
    "prediction_class = np.argmax(predictions[0])\n",
    "call_model_args = {class_idx_str: prediction_class}\n",
    "\n",
    "print(\"Prediction class: \" + str(prediction_class))  # Should be a doberman, class idx = 236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Gradient \n",
    "The code below gives an example on explaning the previous model with Vanilla Gradient (Gradient explanation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the saliency object. This alone doesn't do anthing.\n",
    "gradient_saliency = saliency.GradientSaliency()\n",
    "\n",
    "# Compute the vanilla mask \n",
    "vanilla_mask_3d = gradient_saliency.GetMask(im, call_model_function, call_model_args)\n",
    "\n",
    "\n",
    "# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
    "vanilla_mask_grayscale = saliency.VisualizeImageGrayscale(vanilla_mask_3d)\n",
    "\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 1\n",
    "UPSCALE_FACTOR = 10\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Render the saliency masks.\n",
    "ShowGrayscaleImage(vanilla_mask_grayscale, title='Vanilla Gradient', ax=P.subplot(ROWS, COLS, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmoothGrad \n",
    "Do the same operations for the SmoothGrad explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the saliency object. This alone doesn't do anthing.\n",
    "\n",
    "\n",
    "# Compute the Smooth mask \n",
    "\n",
    "\n",
    "\n",
    "# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
    "\n",
    "\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 1\n",
    "UPSCALE_FACTOR = 10\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Render the sSmooth masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients & SmoothGrad\n",
    "\n",
    "For saliency methods that compute gradients along a path (e.g. Integrated Gradients), we can pass a batch_size parameter, which will batch the different steps along the path together so that the model isn't called for each individual step. When using this parameter, be sure that you are not overloading memory, as a very large batch size could crash the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the saliency object. This alone doesn't do anthing.\n",
    "integrated_gradients = \n",
    "\n",
    "# Baseline is a black image.\n",
    "\n",
    "\n",
    "# Compute the integrated gradient mask and the smoothed mask.\n",
    "\n",
    "# Smoothed mask for integrated gradients will take a while since we are doing nsamples * nsamples computations.\n",
    "\n",
    "\n",
    "# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
    "\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 2\n",
    "UPSCALE_FACTOR = 10\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Render the saliency masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XRAI Full and Fast\n",
    "\n",
    "XRAI is another visualization approach described in [this article](https://arxiv.org/abs/1906.02825). It is a  region-based attribution method,that builds upon integrated gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the saliency object. This alone doesn't do anthing.\n",
    "\n",
    "\n",
    "# Compute XRAI attributions with default parameters\n",
    "\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 3\n",
    "UPSCALE_FACTOR = 20\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Show original image\n",
    "\n",
    "\n",
    "# Show XRAI heatmap attributions\n",
    "\n",
    "\n",
    "# Show most salient 30% of the image\n",
    "mask = xrai_attributions > np.percentile(xrai_attributions, 70)\n",
    "im_mask = np.array(im_orig)\n",
    "im_mask[~mask] = 0\n",
    "ShowImage(im_mask, title='Top 30%', ax=P.subplot(ROWS, COLS, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XRAIParameters and set the algorithm to fast mode which will produce an approximate result.\n",
    "xrai_params = saliency.XRAIParameters()\n",
    "xrai_params.algorithm = 'fast'\n",
    "\n",
    "# Compute XRAI attributions with fast algorithm\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 3\n",
    "UPSCALE_FACTOR = 20\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Show original image\n",
    "\n",
    "\n",
    "# Show XRAI heatmap attributions\n",
    "\n",
    "\n",
    "# Show most salient 30% of the image\n",
    "mask = xrai_attributions_fast > np.percentile(xrai_attributions_fast, 70)\n",
    "im_mask = np.array(im_orig)\n",
    "im_mask[~mask] = 0\n",
    "ShowImage(im_mask, 'Top 30%', ax=P.subplot(ROWS, COLS, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Grad-CAM and Smoothgrad with Grad-CAM.\n",
    "\n",
    "# Construct the saliency object. This alone doesn't do anthing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
    "\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 2\n",
    "UPSCALE_FACTOR = 10\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Render the saliency masks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
